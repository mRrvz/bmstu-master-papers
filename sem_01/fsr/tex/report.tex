\documentclass[12pt, a4paper]{article}

\include{preamble}

\begin{document}


\noindent УДК~004.451.3

\hfill

\noindent \textbf{Объединение страниц оперативной памяти, содержащих одинаковые данные, сжатых модулем ядра Linux}

\noindent А.~В.~Романов$^{1}$\hfill romanov.alexey2000@gmail.com

\noindent $^{1}$МГТУ им.~Н.~Э.~Баумана, Москва, Россия

\hfill

\noindent \textbf{Аннотация}

\noindent Статья посвящена оптимизациям в подсистеме управления памяти в ядре Linux. Кратко описаны главные концепции управления памятью в ядре Linux. Описаны структуры данных и алгоритм работы модуля ядра zram, отвечающего за сжатие страниц оперативной памяти. Разработан метод объединения страниц оперативной памяти содержащие одинаковые данные, которые предварительно были сжаты соответствующим модулем ядра Linux. Проведён анализ результатов работы разработанного алгоритма на различных архитектурах процессора и на разных входных данных.

\noindent \textbf{Ключевые слова}

\noindent \textit{операционные системы, ядро Linux, управление памятью, zram, сжатие данных, дедупликация данных}

\hfill

\section*{Введение}

Существует несколько способов увеличения количества оперативной памяти. Один из способов заключается в физическом увеличении количества планок ОЗУ в системе. Данный способ подразумевает покупку и установку планок ОЗУ, что требует денежных затрат. Кроме физического способа увеличения количества памяти, существуют программные способы увеличения количества ОЗУ, например, сжатие данных. Данный способ требует только вычислительные мощности CPU. Кроме того, к программным способам, можно отнести дедупликацию данных -- объединение участков в памяти, содержащих одинаковые данные, в одно целое. Два последних способа можно объединить и получить ещё один наиболее эффективный способ увеличения количества оперативной памяти: дедупликация сжатых данных.

\section{Управление памятью в ядре Linux}

Ядро Linux использует страничную организацию памяти. Суть этого метода заключается в том, что вся физическая память разделена на страницы одинакового размера, называющиеся страницами памяти. Чаще всего, размер такой страницы равен 4096 байт, но это число является архитектурно зависимым, и может отличаться от архитектуры к архитектуре. В Linux оно задано константой \texttt{PAGE\_SIZE}.

Благодаря механизму страничной организации памяти реализуется механизм виртуальной памяти. Виртуальная память -- метод управления памятью, при котором физический адрес каждой ячейки памяти автоматически (обычно аппаратно) транслируется в некоторый логический адрес и наоборот. Каждое такое соответствие однозначно. При таком методе управления памятью, программы всегда взаимодействуют с логическими адресами. Благодаря этому, в ядре Linux решаются следующие задачи:

\begin{itemize}
	\item изоляция адресного пространства процессов друг от друга;
	\item возможность использовать больше оперативной памяти, чем её установлено в системе;
	\item устранение необходимости управлять общим адресным пространством.
\end{itemize}

Каждая физическая страница памяти в исходном коде ядра Linux описывается структурой \texttt{struct page}, которая представлена в листинге \ref{code:struct_page}. Представлены лишь наиболее важные поля структуры -- большая часть полей структуры используется в различных ситуациях по разному, поэтому описывать их здесь не имеет смысла.

\begin{code}
	\captionof{listing}{Структура \texttt{struct page}}
	\label{code:struct_page}
	\inputminted
	[
	frame=single,
	framerule=0.5pt,
	framesep=20pt,
	fontsize=\small,
	tabsize=4,
	linenos,
	numbersep=5pt,
	xleftmargin=10pt,
	]
	{text}
	{code/struct_page.c}
\end{code}

Опишем подробно поля, указанные в листинге рассматриваемой структуры:

\begin{itemize}
	\item \texttt{flags} -- переменная, содержащая флаги, описывающие данную страницу памяти;
	\item \texttt{private} -- специальное поле для хранения различных данных;
	\item \texttt{\_refcount} -- счетчик ссылок на страницу;
	\item \texttt{\_mapcount} -- количество записей таблицы страниц, ссылающихся на страницу;
	\item \texttt{lru} -- указатель на двунаправленный список давно неиспользуемых страниц.
\end{itemize}

\section{Структуры данных и схема работы модуля ядра zram}

zram -- модуль ядра Linux, предназначенный для сжатия содержимого страниц оперативной памяти на лету и дальнейшего их сохранения в памяти. При использовании этого модуля можно увеличить эффективный размер оперативной памяти системы. Так, например, если некоторая система физически ограничена оперативной памятью размером 4 гигабайта, при среднем коэффициент сжатия $k = \frac{1}{2}$ эффективный размер оперативной памяти увеличивается до 8 гигабайт. Но, стоит отметить: из-за того что сжатие -- затратная операция (с точки зрения CPU), рассматриваемый модуль ядра чаще всего используют в ситуациях, когда в системе мало свободной оперативной памяти. В противном случае, при попытках сжатия всей доступной  памяти, это бы приводило к уменьшению отзывчивости системы.

Единицей диспетчеризации zram является страница памяти. То есть, данный модуль работает со страницами памяти (со структурой \texttt{struct page}), сжимая данные, которые в них хранятся. Модуль zram создает специальное блочное устройство, находящееся в оперативной памяти, которое обрабатывает страницы памяти. Так, например, при попытке записи какого-либо файла в такое блочное устройство, содержимое файла будет разбито на страницы размером \texttt{PAGE\_SIZE}, которые в последствии будут сжаты и сохранены в оперативной памяти.

Каждая сжатая страница внутри модуля ядра zram описывается структурой \texttt{struct zram\_table\_entry}, которая представлена в листинге \ref{code:zram_table_entry}. Массив таких структур хранится внутри структуры \texttt{struct zram}.

\begin{code}
	\captionof{listing}{Структура \texttt{struct zram\_table\_entry}}
	\label{code:zram_table_entry}
	\inputminted
	[
	frame=single,
	framerule=0.5pt,
	framesep=20pt,
	fontsize=\small,
	tabsize=4,
	linenos,
	numbersep=5pt,
	xleftmargin=10pt,
	]
	{text}
	{code/zram_table_entry.c}
\end{code}

Опишем поля рассматриваемой структуры:

\begin{itemize}
	\item \texttt{handle} -- некоторое закодированное число, ссылка на адрес в памяти, где хранится сжатые данные исходной страницы памяти;
	\item \texttt{element} -- если исходная страница состоит из одного и того же элемента, то сохраняется только этот элемент. Так, например, если каждый байт страницы равен нулю, то в поле element будет сохранено 0;
	\item \texttt{flags} -- флаги, описывающие сжатую страницу памяти. Например, если страница состоит из одинаковых элементов, она будет помечена специальным флагом -- то есть у переменной \texttt{flags} будет выставлен некоторый бит, отвечающий за этот флаг;
\end{itemize}

zram использует специально спроектированный аллокатор zsmalloc, целью которого является эффективное распределение памяти при маленьком количестве свободной оперативной памяти. В отличии от наиболее используемого подхода, когда пользователь запрашивает у аллокатора участок памяти размера $n$ и на выходе получает указатель на начало этого участка, zsmalloc возвращает некоторое целое без знаковое число, являющееся специальным образом закодированным указателем на необходимую область памяти. Далее, необходимо передать это число в специальную функцию, представленной в интерфейсе аллокатора, и только после этого получить необходимый адрес на запрашиваемый участок памяти. Такая особенность связана с внутренней реализацией zsmalloc, и позволяет добиться наиболее эффективного распределения памяти. В листинге \ref{code:zsmalloc_api} представлено API для работы с данным аллокатором.

\begin{code}
	\captionof{listing}{API для работы с zsmalloc}
	\label{code:zsmalloc_api}
	\inputminted
	[
	frame=single,
	framerule=0.5pt,
	framesep=20pt,
	fontsize=\small,
	tabsize=4,
	linenos,
	numbersep=5pt,
	xleftmargin=10pt,
	]
	{text}
	{code/zsmalloc_api.c}
\end{code}

Рассмотрим подробнее API для работы с аллокатором zsmalloc:

\begin{itemize}
	\item \texttt{zs\_create\_pool} -- создать некоторый пулл, в котором в дальнейшем будут выделяться объекты;
	\item \texttt{zs\_destroy\_pool} -- уничтожить пулл объектов;
	\item \texttt{zs\_malloc} -- выделить объект размером \texttt{size} внутри пулла \texttt{pool}. Возвращает целое без знаковое число;
	\item \texttt{zs\_free} -- освободить ранее выделенный функцией \texttt{zs\_malloc} объект;
	\item \texttt{zs\_map\_object} -- получить соответствие между числом (\texttt{handle}), которое вернула функция \texttt{zs\_malloc} и указателем на выделенную областью памяти, то есть получить указатель на начало выделенного аллокатором участка памяти. Из-за внутренних особенностей архитектуры zsmalloc, в один момент времени может быть получено не более одного соответствия между \texttt{handle} и указателем на выделенную область памяти;
	\item \texttt{zs\_unmap\_object} -- убрать соответствие между \texttt{handle} и адресом на выделенную акллокатором память. После вызова этой функции, обращаться к выделенному участку памяти запрещено. 
\end{itemize}

Таким образом, поле \texttt{handle} структуры \texttt{struct zram\_table\_entry} -- это закодированный указатель на область памяти, который вернула функция \texttt{zs\_malloc}, в которой хранятся сжатые данные страницы, доступ к которым можно получить с помощью функции \texttt{zs\_map\_object}.

На рисунке \ref{fig:zram} представлена концептуальная схема работы модуля ядра zram и его взаимодействие со всей системой.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{img/zram-arch.pdf}
	\caption{Схема работы модуля ядра zram}
	\label{fig:zram}
\end{figure}

Приведем алгоритм работы zram при попытки записи в блочное устройство:

\begin{enumerate}
	\item содержимое каждой страницы памяти, попавшее в блочное устройство, сжимается и записывается во временный буффер;
	\item у аллокатора zsmalloc запрашивается участок памяти, с помощью функции \texttt{zs\_malloc}, равный размеру сжатых данных;
	\item происходит сопоставление закодированного указателя \texttt{handle} и выделенной областью памяти с помощью функции \texttt{zs\_map\_object};
	\item сжатые данные копируются из временного буффера, в область памяти выделенную аллокатором. Временный буффер освобождается.
	\item заполняется соответствующая ячейка массива структур \texttt{zram\_table\_entry}. В структуре сохраняется указатель на объект --  \texttt{handle} и в переменную \texttt{flags} устанавливаются флаги, описывающие сжатые данные обрабатываемой страницы. 
\end{enumerate}

Алгоритм чтения из блочного устройства аналогичен алгоритму записи.

\section{Алгоритм объединения содержимого страниц оперативной памяти}

Рассмотрим ситуацию, представленную на рисунке \ref{fig:zram-duplicates}. 

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{img/zram-duplicates.pdf}
	\caption{Страницы с одинаковым содержимым}
	\label{fig:zram-duplicates}
\end{figure}

Три страницы с одинаковым содержимым соответствуют трём разным структурам \texttt{struct zram\_table\_entry}, которые в свою очередь хранят закодированный указатель на данные. Сжатые данные, хранящиеся внутри аллокатора zsmalloc, дублируют друг друга. В данном примере, при сжатом размере страницы равным $n$ байт, модуль zram использует $3 * n$ байт памяти, вместо того чтобы использовать $n$ байт. 
Этого можно добиться заменив закодированные указатели \texttt{handle Y} и \texttt{handle Z} на \texttt{handle X}, освободить участки памяти внутри zsmalloc, на которые они указывают и добавить счётчик ссылок на объект, на который указывает \texttt{handle X}. Таким образом, можно сохранить $2 * n$ байт оперативной памяти. Данная оптимизация представлена на рисунке \ref{fig:zram-no-duplicates}.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{img/zram-no-duplicates.pdf}
	\caption{Дедупликация данных}
	\label{fig:zram-no-duplicates}
\end{figure}

Алгоритм дедупликации сжатых данных можно описать следующим образом;

\begin{enumerate}
	\item создать хэш-таблицу размерностью $n$, где $n$ -- размер массива структур \texttt{struct zram\_table\_entry};
	\item инициализировать красно-черное дерево, которое будет хранить узлы вида $(key,\ value)$;
	\item начать итерироваться по массиву структур \texttt{struct zram\_table\_entry};
	\item с помощью функции \texttt{zs\_map\_object} получить указатель на область памяти, в которой хранятся сжатые данные, на которые указывает очередной элемент массива с индексом $index$;
	\item скопировать данные во временный буффер и вычислить для них хэш-сумму $h$;
	\item проверить, пуста ли ячейка хэш-таблицы с индексом $i = h \ mod \ n$;
	\item если ячейка пуста, то добавить в неё индекс $index$ и перейти к обработке следующего элемента массива;
	\item в обратном случае, достать из ячейки хэш-таблицы индекс $index_{hash}$ и получить соответствующий элемент массива структур;
	\item повторить шаги г) и д) для этого элемента массива;
	\item сравнить две полученные хэш-суммы;
	\item в случае их несовпадения, перейти к обработке следующего элемента массива;
	\item в обратном случае, с помощью функции \texttt{zs\_free} освободить участок памяти, на который указывает элемент массива с индексом $index$;
	\item заменить указатель $handle$ у элемента массива с индексом $index$ на соответствующий указатель $handle_{hash}$ структуры с индексом $index_{hash}$;
	\item проверить наличие в красно-черном дереве узла с ключом $k = handle_{hash}$;
	\item если узел уже есть в дереве, инкрементировать значение, хранимое в этом узле (счётчик ссылок на объект $handle_{hash}$);
	\item в обратном случае, добавить в дерево узел с ключом $k = handle_{hash}$ и значение $v = 2$ (так как на объект с $handle_{hash}$ на данный момент времени ссылаются два элемента массива);
	\item перейти к обработке следующего элемента массива структур.
\end{enumerate}

Красно-черное дерево необходимо для дальнейшей корректной работы системы. Без него, при попытке освобождения области памяти, выделенной аллокатором, невозможно узнать, ссылается ли кто-либо ещё на эту область памяти. Это может привести к непредсказуемым последствиям для всей системы и ядра в целом. 

При освобождении одного из элемента массива структур \texttt{struct zram\_table\_entry}, например при прочтении страницы из блочного устройства, необходимо проверить наличие в дереве узла с соответствующем ключом, и, в случае если узел найден, декрементировать значение, хранимое в узле (счётчик ссылок на область памяти). Если счётчик равен нулю (или если узел не найден в дереве), необходимо удалить узел из дерева и с помощью функции \texttt{zs\_free} освободить область памяти.

Отличительной чертой красно-черного дерева является быстрый поиск и относительно долгое удаление и добавление узлов (из-за того что дерево каждый раз приходиться балансировать). В силу особенности реализации алгоритма, в дереве чаще будет производиться поиск, чем удаление или добавление, поэтому для реализации алгоритма было выбрано именно красно-черное дерево, а, например, не обычное бинарное дерево поиска.

Алгоритм реализован в виде отдельной функции, которую можно вызвать из пространства пользователя. Таким образом, пользователь сам должен определить подходящий момент для соответствующего вызова. Описанный алгоритм может быть переделан таким образом, чтобы хэш-сумма считалась при первичной обработке страницы -- то есть в тот момент, когда исходная страница только попадает в блочное устройство в несжатом виде. Но, в таком случае, если система работает с разными данными (мало страниц-дубликатов), zram будет тратить процессорное время на вычисление хеш-сумм в пустую, что ухудшит производительность всей системы. Разработанный подход возлагает ответственность за запуск алгоритма на пространство пользователя, с надеждой что алгоритм будет запущен в тот момент, когда внутри блочного устройства уже находится большее количество страниц-дубликатов.

\section{Сравнительный анализ скорости работы разработанного алгоритма}

Очевидно, что алгоритм эффективен (по памяти) только в ситуациях, когда в системе имеются дубликаты. Чем их больше, тем сильнее разработанный алгоритм увеличивает эффективный размер оперативной памяти. Поэтому, сравним скорость работы алгоритма при различных состояниях системы на различных устройствах. Тестирование проводилось на трёх устройствах:

\begin{enumerate}
	\item Система на одном чипе (англ. SoC -- System on Chip) с 4-мя ядрами Cortex-A35:
	
	\begin{itemize}
		\item Имя устройства: Amlogic SOC S905Y4
		\item Процессор: 4 ядра ARM Cortex-A35 @ 2.3 GHz
		\item Память: 4 ГБ DDR4.
	\end{itemize}
	
	\item SoC с 2-мя ядрами Cortex-A35:
	
	\begin{itemize}
		\item Имя устройства: Amlogic SOC A113L
		\item Процессор: 2 ядра ARM Cortex-A35 @ 2.3 GHz
		\item Память: 128 МБ DDR4.
	\end{itemize}
	
	\item Персональный компьютер с 8-ми ядерным процессором AMD Ryzen 7
	
	\begin{itemize}
		\item Имя устройства: персональный компьютер
		\item Процессор: AMD Ryzen 7 3700X 8-Core Processor
		\item Память: 16 ГБ DDR4.
	\end{itemize}
\end{enumerate}

Алгоритм был протестирован в двух состояниях системы:

\begin{itemize}
	\item в системе более 25\% всех данных -- дубликаты;
	\item дубликаты составляют менее 1\% от общего количества данных.
\end{itemize}

В таблице \ref{tbl:results} представлены результаты проведенного тестирования. В ячейках таблицы указано время (в секундах), потраченное на работу алгоритма. Размер исходных данных -- 128 МБ.

\begin{table}[ht]
	\small
	\caption{Результаты тестирования разработанного алгоритма на различных устройствах}
	\label{tbl:results}
	\begin{tabular}{|l|l|l|l|}
		\hline
		Устройство & S905Y4 & A113L & ПК \\ \hline
		25\% дубликатов & 2.4 сек & 2.5 сек & 0.45 сек \\ \hline
		1\% дубликатов & 2.2 сек & 2.34 сек & 0.4 сек \\ \hline
	\end{tabular}
\end{table}

В таблице \ref{tbl:time} представлено время (в секундах), потраченное на сжатие данных, попавших в блочное устройство, созданное модулем ядра zram. Размер исходных данных -- 128 МБ. 

\begin{table}[ht]
	\small
	\caption{Время потраченное на сжатие данных}
	\label{tbl:time}
	\begin{tabular}{|l|l|l|l|}
		\hline
		Устройство & S905Y4 & A113L & ПК \\ \hline
		25\% дубликатов & 23.1 сек & 40.5 сек & 5.2 сек \\ \hline
		1\% дубликатов & 24.1 сек & 39.1 сек & 5.7 сек \\ \hline
	\end{tabular}
\end{table}

По представленным результатам из таблицы \ref{tbl:results} можно сделать вывод о том, что разработанный алгоритм неэффективен когда в системе находится небольшое количество страниц дубликатов -- процессорное время тратится на подсчёт хэш-сумм, но из-за того что дубликатов в системе практически нет, количество доступной (эффективной) оперативной памяти, за счёт объединения страниц, не увеличивается. Это обусловлено тем, что объединение страниц не происходит. В итоге, в замен на потраченное процессорное время система не получает ничего.

В обратном случае, когда в системе находится 25\% страниц-дубликатов, алгоритм отрабатывает практически с такой же скоростью, как и в случае если в системе таких страниц менее 1\%. Но, в этом случае, система получает выигрыш в виде увеличения объема доступной оперативной памяти.

Кроме того, можно отметить, что скорость работы алгоритма сильно зависит от мощности CPU -- чем больше частота процессора, тем быстрее работает алгоритм. При этом, скорость разработанного алгоритма не зависит от количества ядер процессора. Это можно объяснить тем, что алгоритм не является параллельным и выполняется на одном ядре.

Из таблицы \ref{tbl:time} можно сделать вывод, что алгоритм работает быстро, как минимум, относительно времени сжатия данных. Алгоритм дедупликации работает быстрее в 10 - 15 раз, чем само сжатие данных. На основе этого, можно сделать вывод о быстродействии алгоритма.

\section*{Заключение}

Были описаны базовые принципы управления памятью в ядре Linux. Рассмотрены структуры данных модуля ядра zram, описан алгоритм его работы. Разработан алгоритм дедупликации сжатых данных в качестве модификации модуля zram. Проведено тестирование скорости работы алгоритма на различных устройствах. 

Разработанный алгоритм оказался относительно неэффективным на системах с маленьким количеством дублирующихся данных. Наоборот, чем больше в системе повторяющихся данных, тем более эффективен разработанный алгоритм. Так же стоит отметить быстродействие алгоритма -- объединение страниц происходит в среднем в 10 - 15 раз быстрее, чем сам процесс сжатия страниц.

Разработанный алгоритм вместе с результатами его работы были отправлены разработчикам ядра Linux и модуля zram \cite{1}. Результаты работы алгоритма были оценены разработчиками положительно, а сама реализация на данный момент находится на этапе code review, и, возможно, в будущем будет добавлена в основную ветку ядра Linux.

\begin{thebibliography}{5}
	\bibitem{1} zram: introduce merge identical pages mechanism - Alexey Romanov [Электронный ресурс]. -- Режим доступа: https://lore.kernel.org/all/20221121190020.66548-1-avromanov@sberdevices.ru/
\end{thebibliography}

\noindent \textbf{Романов Алексей Васильевич} — студент, МГТУ им. Н. Э. Баумана, кафедра «Программное обеспечение ЭВМ и информационные технологии».


\end{document}
